{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>A COMPARISON OF<br>ENSEMBLE LEARNING METHODS<br>IN RETAIL SALES FORECASTING</h1>\n",
    "<b>by Serhan SÃœER</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>1. Introduction</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T09:54:39.846992Z",
     "start_time": "2019-09-04T09:54:37.781591Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "\n",
    "from math import sqrt\n",
    "import statistics\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import category_encoders as ce\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = None\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the data files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T09:54:40.827048Z",
     "start_time": "2019-09-04T09:54:40.396832Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\", sep=',', header=0, \n",
    "                    names=['store_id', 'department_id', 'date', 'weekly_sales', 'is_holiday'])\n",
    "\n",
    "features = pd.read_csv(\"data/features.csv\", sep=',', header=0, \n",
    "                       names=['store_id', 'date', 'temperature', 'fuel_price', 'markdown_1', 'markdown_2', \n",
    "                              'markdown_3', 'markdown_4', 'markdown_5', 'cpi', 'unemployment', 'is_holiday'])\n",
    "\n",
    "stores = pd.read_csv(\"data/stores.csv\", sep=',', header=0, \n",
    "                     names=['store_id', 'type', 'store_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(features.shape)\n",
    "print(stores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging all data files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T09:54:43.363395Z",
     "start_time": "2019-09-04T09:54:43.075151Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.merge(train, features, on=['store_id', 'date', 'is_holiday'], how='left')\n",
    "data = pd.merge(data, stores, on=['store_id'], how='left')\n",
    "del train, features, stores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting data by date/store number/department number, moving date column to the beginning and weekly_sales column to the end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T09:54:45.128069Z",
     "start_time": "2019-09-04T09:54:44.595521Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = data.sort_values(['date', 'store_id', 'department_id']).reset_index(drop=True)\n",
    "data = pd.concat([data.date, data.drop('date', axis=1)], axis=1)\n",
    "data = pd.concat([data.drop('weekly_sales', axis=1), data.weekly_sales], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The merged data contains 421570 rows and 16 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the first 5 rows of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.apply(lambda x: [x.nunique()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.apply(lambda x: [x.unique()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2. Exploratory Data Analysis</h1><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2.1. Univariate Analysis</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = data[['date', 'store_id', 'department_id', 'is_holiday', 'type']]\n",
    "nums = data.drop(cats.columns, axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>- Categorical</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Categorical Variables':cats.columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_cats(dataframe, column_name):\n",
    "    print('-' * 100 + '\\n' + 'Number of Unique Values:')\n",
    "    print(str(dataframe[column_name].nunique()) + '\\n' + '-' * 100)\n",
    "    print('Unique Values:')\n",
    "    print(np.sort(dataframe[column_name].unique()), '\\n' + '-' * 100)\n",
    "    uniques = list(dataframe[column_name].value_counts().index)\n",
    "    counts = list(dataframe[column_name].value_counts().values)\n",
    "    percentages = list(dataframe[column_name].value_counts(normalize=True).values)\n",
    "    freq_table_list =  list(zip(uniques, counts, percentages))\n",
    "    freq_table = pd.DataFrame(freq_table_list, columns = [column_name.capitalize(), 'Count' , 'Count%'])\n",
    "    plt.figure(figsize=(18, 8))\n",
    "    if len(dataframe[column_name].unique()) < 5:\n",
    "        display(freq_table, dataframe[column_name].value_counts(normalize = True).plot(kind='pie', \n",
    "                                                          labels=dataframe[column_name].unique(), \n",
    "                                                          autopct='%1.1f%%', \n",
    "                                                          startangle=90))\n",
    "    else:\n",
    "        display(freq_table, dataframe[column_name].value_counts(normalize = True).plot(kind='bar', legend=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>date</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analyze_cats(data, 'date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset consists of weekly sales of Wallmart Stores from 2010-02-05 to 2012-10-26.  \n",
    "So time period of the data can be considered as 2 years and 9 months or 143 weeks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>store_id</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analyze_cats(data, 'store_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 45 Wallmart Stores in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>department_id</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analyze_cats(data, 'department_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset contains 81 different departments in the stores.  \n",
    "Furthermore, it can be understood that while some departments exists in most of stores, some exists in only few stores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>is_holiday</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analyze_cats(data, 'is_holiday')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs shows that \"is_holiday\" variable is highly unbalanced since 93% of the weekly sales did not occur in the holidays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>type</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analyze_cats(data, 'type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While roundly half of the weekly sales records are related to Type A stores, almost 40% of them occurred in Type B stores and Type C stores have only 10 percentage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>- Numerical</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Numerical Variables':nums.columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nums.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Features':nums.var().index, 'Variance':nums.var().values}).sort_values('Variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Features':(nums.std() / nums.mean()).index, \n",
    "              'CV':(nums.std() / nums.mean()).values}).sort_values('CV', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Features':nums.skew().index, 'Skewness':nums.skew().values}).sort_values('Skewness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Features':nums.kurtosis().index, 'Kurtosis':nums.kurtosis().values}).sort_values('Kurtosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in nums.columns:\n",
    "    plt.figure(figsize=(12, 2))\n",
    "    sns.distplot(nums[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nums.hist(figsize=(20, 15), bins=20, xlabelsize=9, ylabelsize=9);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in nums.columns:\n",
    "    plt.figure(figsize=(12, 2))\n",
    "    sns.boxplot(x=nums[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2.2. Bivariate Analysis</h2><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>- Categorical & Numerical</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats['is_holiday'] = cats['is_holiday'].replace({False:0, True:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats['type'] = cats['type'].replace({'A':3, 'B':2, 'C':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = cats.astype({'date':'category'})\n",
    "cats['date'] = cats['date'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cats.columns:\n",
    "    print(i)\n",
    "    print(stats.kruskal(cats[i], nums['weekly_sales']))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to Kruskal Wallis test result, sample distributions in the categorical variables are not equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>- Numerical & Numerical</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation Analysis based on \"Spearman\" method will be used since numerical features don't have gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(round(abs(nums.corr(method ='spearman')), 2), vmin=0, vmax=1, \n",
    "            center=0.5, annot=True, cmap=plt.cm.Reds, square=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(abs(nums.corr(method ='spearman')), 2)[round(abs(nums.corr(method ='spearman')), 2) > 0.7] \\\n",
    "    [round(abs(nums.corr(method ='spearman')), 2) < 1.0].dropna(how='all', axis=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in nums.drop('weekly_sales', axis=1).columns:\n",
    "    plt.figure(figsize=(12, 2))\n",
    "    sns.scatterplot(x=i, y=\"weekly_sales\", data=nums);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2.3. Multivariate Analysis</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Multivariate Analysis, ANCOVA will be used since data has both categorical and numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.BinaryEncoder(cols=['date', 'store_id', 'department_id', 'type'], drop_invariant=True)\n",
    "\n",
    "cats = encoder.fit_transform(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = \" + \".join(pd.concat([cats, nums], axis=1).columns)[:-15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"weekly_sales ~ \" + \" + \".join(pd.concat([cats, nums], axis=1).columns)[:-15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ols(formula, data=pd.concat([cats, nums], axis=1)).fit()\n",
    "\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>3. Methodology</h1><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3.1. Data Preprocessing</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, variables will be split into two sets as \"features\" and \"target\" in order to implement preprocessing easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T09:55:00.740423Z",
     "start_time": "2019-09-04T09:55:00.559443Z"
    }
   },
   "outputs": [],
   "source": [
    "features = data.drop('weekly_sales', axis=1)\n",
    "target = pd.DataFrame(data['weekly_sales'], columns=['weekly_sales'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>- Missing Value Treatment</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T09:55:04.496037Z",
     "start_time": "2019-09-04T09:55:04.456438Z"
    }
   },
   "outputs": [],
   "source": [
    "features[['markdown_1','markdown_2','markdown_3','markdown_4', 'markdown_5']] = \\\n",
    "    features[['markdown_1','markdown_2','markdown_3','markdown_4', 'markdown_5']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>- Outlier Treatment</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifying the outliers in continuous variables based on IQR Score Method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def find_outliers(data, column_list):\n",
    "    for i in column_list:\n",
    "        Q1 = data[i].quantile(0.25)\n",
    "        Q3 = data[i].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        print(i + ' ' * (13 - len(i)) + ': ' + \n",
    "              str(len(data[i][(data[i] < (Q1 - 3 * IQR)) | (data[i] > (Q3 + 3 * IQR))])))\n",
    "        \n",
    "find_outliers(features, features.select_dtypes(include=['int64', 'float64']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_outliers(features[features > 0], ['markdown_1', 'markdown_2', 'markdown_3', 'markdown_4', 'markdown_5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_outliers(target, ['weekly_sales'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>- Feature Engineering</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T09:55:06.881852Z",
     "start_time": "2019-09-04T09:55:06.614794Z"
    }
   },
   "outputs": [],
   "source": [
    "features = features.astype({'date':'datetime64'})\n",
    "features['week_number'] = features['date'].dt.week\n",
    "features = features.drop('date', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>- Label Encoding</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T09:55:10.590038Z",
     "start_time": "2019-09-04T09:55:10.471648Z"
    }
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "features['is_holiday'] = le.fit_transform(features['is_holiday'])\n",
    "features['type'] = le.fit_transform(features['type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>- Feature Selection</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(features[features['is_holiday'] == True]['week_number'].unique()))\n",
    "print(sorted(features[features['is_holiday'] == False]['week_number'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since \"week_number\" represents the information which \"is_holiday\" variable offers, \"is_holiday\" will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T09:55:16.365101Z",
     "start_time": "2019-09-04T09:55:16.305726Z"
    }
   },
   "outputs": [],
   "source": [
    "features = features.drop('is_holiday', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Based on Pairwise Correlation</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data = round(abs(pd.concat([features, target], axis=1).corr(method ='spearman')), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(corr_data, vmin=0, vmax=1, center=0.5, annot=True, cmap=plt.cm.Reds, square=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr_data[corr_data > 0.7][corr_data < 1.0].dropna(how='all', axis=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Features':corr_data['weekly_sales'].sort_values(ascending=False).index, \n",
    "              'Corr. with Target':corr_data['weekly_sales'].sort_values(ascending=False).values}).drop(0, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since \"markdown_4\" and \"store_size\" features have higher correlation with the target, other variables having high correlation will be dropped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T09:55:18.820222Z",
     "start_time": "2019-09-04T09:55:18.803321Z"
    }
   },
   "outputs": [],
   "source": [
    "features = features.drop(['markdown_3', 'markdown_2', 'markdown_5', 'markdown_1', 'type'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Based on Variance</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Features':features.var().index, 'Variance':features.var().values}).sort_values('Variance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since \"fuel_price\" has very low variation, it will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T09:55:23.489266Z",
     "start_time": "2019-09-04T09:55:23.471441Z"
    }
   },
   "outputs": [],
   "source": [
    "features = features.drop('fuel_price', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Based on Feature Importance</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(random_state=1)\n",
    "model.fit(features, target)\n",
    "feat_importances = pd.Series(model.feature_importances_, index=features.columns)\n",
    "plt.figure(figsize=(12, 6))\n",
    "feat_importances.sort_values().plot(kind='barh', grid=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Features':feat_importances.sort_values(ascending=False).index, \n",
    "              'Importances':feat_importances.sort_values(ascending=False).values})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to feature importance output, 'markdown_4' will be dropped since it doesn't have a significant feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T09:55:25.454384Z",
     "start_time": "2019-09-04T09:55:25.441407Z"
    }
   },
   "outputs": [],
   "source": [
    "features = features.drop('markdown_4', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>- One Hot Encoding</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the scope of this study contains only tree-based models, one hot encoding will not be applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>- Feature Scaling</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the scope of this study contains only tree-based models, feature scaling will not be applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>- Train-Test Split</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T09:55:27.724702Z",
     "start_time": "2019-09-04T09:55:27.588632Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train_val, x_test, y_train_val, y_test = train_test_split(features, target, test_size=0.2, random_state=0)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x_train : {0:.{1}f}%'.format(x_train.shape[0] / features.shape[0] * 100, 0))\n",
    "print('y_train : {0:.{1}f}%'.format(y_train.shape[0] / target.shape[0] * 100, 0))\n",
    "print('\\n')\n",
    "print('x_val   : {0:.{1}f}%'.format(x_val.shape[0] / features.shape[0] * 100, 0))\n",
    "print('y_val   : {0:.{1}f}%'.format(y_val.shape[0] / target.shape[0] * 100, 0))\n",
    "print('\\n')\n",
    "print('x_test  : {0:.{1}f}%'.format(x_test.shape[0] / features.shape[0] * 100, 0))\n",
    "print('y_test  : {0:.{1}f}%'.format(y_test.shape[0] / target.shape[0] * 100, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3.2. Model Building</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>A. Bootstrap Aggregation</b>  \n",
    "--- Bagging (BaggingRegressor)  \n",
    "--- Random Forest (RandomForestRegressor)  \n",
    "--- Extremely Randomized Trees (ExtraTreesRegressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>B. Boosting</b>  \n",
    "--- Adaptive Boosting (AdaBoostRegressor)  \n",
    "--- Extreme Gradient Boosting (XGBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>C. Stacked Generalization</b>  \n",
    "--- Voting Regressor (VotingRegressor)  \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to obtain reasonable comparison, the maximum depths of the model was selected same in all models as 7 for the beginning.  \n",
    "Different values of depth will be tried in the stage of hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'Bagging' : BaggingRegressor(base_estimator=DecisionTreeRegressor(max_depth=7, random_state=1), \n",
    "                                       n_estimators=100, \n",
    "                                       n_jobs=-1, \n",
    "                                       random_state=1), \n",
    "          'Random F.' : RandomForestRegressor(n_estimators=100, \n",
    "                                              max_depth=7, \n",
    "                                              n_jobs=-1, \n",
    "                                              random_state=1),\n",
    "          'Extra T.' : ExtraTreesRegressor(n_estimators=100, \n",
    "                                           max_depth=7, \n",
    "                                           n_jobs=-1, \n",
    "                                           random_state=1),\n",
    "          'AdaBoost' : AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=7, random_state=1), \n",
    "                                         n_estimators=100, \n",
    "                                         learning_rate=0.1, \n",
    "                                         random_state=1),\n",
    "          'XGBoost' : xgb.XGBRegressor(n_estimators=100, \n",
    "                                       learning_rate=0.1,\n",
    "                                       max_depth=7, \n",
    "                                       n_jobs=-1, \n",
    "                                       random_state=1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = list(models.keys())\n",
    "mae_scores = []\n",
    "rmse_scores = []\n",
    "r2_scores = []\n",
    "times = []\n",
    "\n",
    "for i in models:\n",
    "    start = time.time()\n",
    "    model = models[i]\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_val)\n",
    "    mae_scores.append(mean_absolute_error(y_val, y_pred))\n",
    "    rmse_scores.append(sqrt(mean_squared_error(y_val, y_pred)))\n",
    "    r2_scores.append(r2_score(y_val, y_pred))\n",
    "    end = time.time()\n",
    "    times.append(end - start)\n",
    "\n",
    "compare_list =  list(zip(model_name, mae_scores, rmse_scores, r2_scores, times))\n",
    "compare = pd.DataFrame(compare_list, columns = ['Model', 'MAE' , 'RMSE', 'R2', 'Time(sec)'])\n",
    "compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In stacked generalization algorithm, XGBoost, AdaBoost and Random Forest will be used since they have higher scores than other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VotingRegressor(estimators=[('xg', xgb.XGBRegressor(n_estimators=100, \n",
    "                                                             learning_rate=0.1, \n",
    "                                                             max_depth=7, \n",
    "                                                             n_jobs=-1, \n",
    "                                                             random_state=1)), \n",
    "                                    ('ad', AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=7, \n",
    "                                                                                                  random_state=1),\n",
    "                                                             n_estimators=100, \n",
    "                                                             learning_rate=0.1, \n",
    "                                                             random_state=1)),\n",
    "                                    ('rf', RandomForestRegressor(n_estimators=100, \n",
    "                                                                 max_depth=7, \n",
    "                                                                 n_jobs=-1, \n",
    "                                                                 random_state=1))], \n",
    "                        n_jobs=-1)\n",
    "\n",
    "model_name.append('VotingReg')\n",
    "models['VotingReg'] = model\n",
    "start = time.time()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_val)\n",
    "mae_scores.append(mean_absolute_error(y_val, y_pred))\n",
    "rmse_scores.append(sqrt(mean_squared_error(y_val, y_pred)))\n",
    "r2_scores.append(r2_score(y_val, y_pred))\n",
    "end = time.time()\n",
    "times.append(end - start)\n",
    "\n",
    "compare_list =  list(zip(model_name, mae_scores, rmse_scores, r2_scores, times))\n",
    "compare = pd.DataFrame(compare_list, columns = ['Model', 'MAE' , 'RMSE', 'R2', 'Time(sec)'])\n",
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare.plot(kind='barh', \n",
    "             x='Model', \n",
    "             y=['MAE' , 'RMSE', 'R2'], \n",
    "             figsize=(14, 8), \n",
    "             logx=True,\n",
    "             grid=True, \n",
    "             legend='reverse');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3.3. Model Evaluation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3.3.1. Performance Metrics</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_second(x):\n",
    "    return x[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Mean Absolute Error</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, j in sorted(zip(model_name, mae_scores), key=take_second, reverse=False):\n",
    "    print(i + ' ' * (12 - len(i)) + ': {0:.{1}f}'.format(j, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare.sort_values('MAE', ascending=False).plot(kind='barh', \n",
    "                                                 x='Model', \n",
    "                                                 y='MAE', \n",
    "                                                 figsize=(12, 6), \n",
    "                                                 legend=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Root Mean Squared Error</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in sorted(zip(model_name, rmse_scores), key=take_second, reverse=False):\n",
    "    print(i + ' ' * (12 - len(i)) + ': {0:.{1}f}'.format(j, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare.sort_values('RMSE', ascending=False).plot(kind='barh', \n",
    "                                                  x='Model', \n",
    "                                                  y='RMSE', \n",
    "                                                  figsize=(12, 6),\n",
    "                                                  legend=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>R-Squared</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in sorted(zip(model_name, r2_scores), key=take_second, reverse=True):\n",
    "    print(i + ' ' * (12 - len(i)) + ': {0:.{1}f}'.format(j, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare.sort_values('R2').plot(kind='barh', \n",
    "                               x='Model', \n",
    "                               y='R2', \n",
    "                               figsize=(12, 6),\n",
    "                               legend=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Runtime</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in sorted(zip(model_name, times), key=take_second, reverse=False):\n",
    "    print(i + ' ' * (12 - len(i)) + ': {0:.{1}f}'.format(j, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare.sort_values('Time(sec)', ascending=False).plot(kind='barh', \n",
    "                                                       x='Model', \n",
    "                                                       y='Time(sec)', \n",
    "                                                       figsize=(12, 6), \n",
    "                                                       legend=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3.3.2. Cross-Validation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to achieve an unbiased estimate of the model performance, 5-fold cross-validation will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_mae_scores = []\n",
    "all_rmse_scores = []\n",
    "all_r2_scores = []\n",
    "all_times = []\n",
    "\n",
    "for i in models:\n",
    "    mae_scores = []\n",
    "    rmse_scores = []\n",
    "    r2_scores = []\n",
    "    times = [] \n",
    "    model = models[i]\n",
    "    cv = KFold(n_splits=5)\n",
    "    for train_index, test_index in cv.split(x_train_val.values):\n",
    "        start = time.time()\n",
    "        x_train, x_val, y_train, y_val = x_train_val.iloc[train_index], x_train_val.iloc[test_index], \\\n",
    "                                            y_train_val.iloc[train_index], y_train_val.iloc[test_index]       \n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_val)    \n",
    "        mae_scores.append(mean_absolute_error(y_val, y_pred))\n",
    "        rmse_scores.append(sqrt(mean_squared_error(y_val, y_pred)))\n",
    "        r2_scores.append(r2_score(y_val, y_pred))\n",
    "        end = time.time()\n",
    "        times.append(end - start)\n",
    "    all_mae_scores.append(sum(mae_scores) / len(mae_scores))\n",
    "    all_rmse_scores.append(sum(rmse_scores) / len(rmse_scores))\n",
    "    all_r2_scores.append(sum(r2_scores) / len(r2_scores))\n",
    "    all_times.append(round(sum(times) / len(times)))\n",
    "\n",
    "compare_list_cv =  list(zip(model_name, all_mae_scores, all_rmse_scores, all_r2_scores, all_times))\n",
    "compare_cv = pd.DataFrame(compare_list_cv, columns = ['Model', 'MAE' , 'RMSE', 'R2', 'Time(sec)'])\n",
    "compare_cv.sort_values('MAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_cv.sort_values('MAE', ascending=False).plot(kind='barh', \n",
    "                                                    x='Model', \n",
    "                                                    y=['MAE' , 'RMSE', 'R2'], \n",
    "                                                    logx=True, \n",
    "                                                    legend='reverse',\n",
    "                                                    figsize=(12, 6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3.3.3. Hyperparameter Optimization</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T21:47:54.941275Z",
     "start_time": "2019-09-04T21:25:26.685497Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-40e6da92d9fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     n_jobs=-1)\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    685\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    664\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 666\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_param = {'n_estimators'     : range(100, 1001, 100), \n",
    "              'learning_rate'    : [0.01, 0.05, 0.1], \n",
    "              'max_depth'        : range(3, 11), \n",
    "              'gamma'            : [0, 1, 5], \n",
    "              'subsample'        : [0.8, 0.9, 1.0], \n",
    "              'colsample_bytree' : [0.8, 0.9, 1.0]}\n",
    "\n",
    "xgb_grid = xgb.XGBRegressor(n_jobs=-1, \n",
    "                            random_state=1)\n",
    "\n",
    "cv = KFold(n_splits=3)\n",
    "\n",
    "grid = GridSearchCV(estimator=xgb_grid,\n",
    "                    param_grid=grid_param,\n",
    "                    scoring='neg_mean_absolute_error',\n",
    "                    cv=cv,\n",
    "                    n_jobs=-1)\n",
    "\n",
    "grid.fit(x_train, y_train)\n",
    "\n",
    "print(grid.best_params_, -grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T18:54:01.851730Z",
     "start_time": "2019-09-07T08:21:09.002910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'n_estimators': 1000} 1452.0846638777512\n"
     ]
    }
   ],
   "source": [
    "grid_param = {'n_estimators' : range(100, 1001, 100),\n",
    "              'max_depth'    : range(3, 11)}\n",
    "\n",
    "xgb_grid = xgb.XGBRegressor(learning_rate=0.3,\n",
    "                            gamma=1,\n",
    "                            subsample=0.8,\n",
    "                            colsample_bytree=1,\n",
    "                            n_jobs=-1, \n",
    "                            random_state=1)\n",
    "\n",
    "cv = KFold(n_splits=5)\n",
    "\n",
    "grid = GridSearchCV(estimator=xgb_grid,\n",
    "                    param_grid=grid_param,\n",
    "                    scoring='neg_mean_absolute_error',\n",
    "                    cv=cv,\n",
    "                    n_jobs=-1)\n",
    "\n",
    "grid.fit(x_train_val, y_train_val)\n",
    "\n",
    "print(grid.best_params_, -grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T21:17:19.753462Z",
     "start_time": "2019-09-04T21:03:26.447170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error : 1321.26\n",
      "R-Square            : 0.98\n",
      "Runtime             : 795sec\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Mean Absolute Error : 1316.63\n",
      "R-Square            : 0.98\n",
      "Runtime             : 833sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = xgb.XGBRegressor(learning_rate=0.05, \n",
    "                         n_estimators=4800,\n",
    "                         max_depth=10,\n",
    "                         n_jobs=-1, \n",
    "                         random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_val)\n",
    "print('Mean Absolute Error : {0:.{1}f}'.format(mean_absolute_error(y_val, y_pred), 2))\n",
    "print('R-Square            : {0:.{1}f}'.format(r2_score(y_val, y_pred), 2))\n",
    "end = time.time()\n",
    "print('Runtime             : {0:.{1}f}sec'.format(end - start, 0))\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "y_pred_test = model.predict(x_test)\n",
    "print('Mean Absolute Error : {0:.{1}f}'.format(mean_absolute_error(y_test, y_pred_test), 2))\n",
    "print('R-Square            : {0:.{1}f}'.format(r2_score(y_test, y_pred_test), 2))\n",
    "end2 = time.time()\n",
    "print('Runtime             : {0:.{1}f}sec'.format(end2 - start, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T10:09:12.200208Z",
     "start_time": "2019-09-04T10:07:12.476388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error : 1424.71\n",
      "R-Square            : 0.98\n",
      "Runtime             : 118sec\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Mean Absolute Error : 1412.67\n",
      "R-Square            : 0.98\n",
      "Runtime             : 120sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = xgb.XGBRegressor(learning_rate=0.3, \n",
    "                         n_estimators=700,\n",
    "                         max_depth=10,\n",
    "                         n_jobs=-1, \n",
    "                         random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_val)\n",
    "print('Mean Absolute Error : {0:.{1}f}'.format(mean_absolute_error(y_val, y_pred), 2))\n",
    "print('R-Square            : {0:.{1}f}'.format(r2_score(y_val, y_pred), 2))\n",
    "end = time.time()\n",
    "print('Runtime             : {0:.{1}f}sec'.format(end - start, 0))\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "y_pred_test = model.predict(x_test)\n",
    "print('Mean Absolute Error : {0:.{1}f}'.format(mean_absolute_error(y_test, y_pred_test), 2))\n",
    "print('R-Square            : {0:.{1}f}'.format(r2_score(y_test, y_pred_test), 2))\n",
    "end2 = time.time()\n",
    "print('Runtime             : {0:.{1}f}sec'.format(end2 - start, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T10:04:11.304068Z",
     "start_time": "2019-09-04T10:01:52.839910Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error : 1486.13\n",
      "R-Square            : 0.98\n",
      "Runtime             : 136sec\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Mean Absolute Error : 1471.06\n",
      "R-Square            : 0.98\n",
      "Runtime             : 138sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = xgb.XGBRegressor(learning_rate=0.3, \n",
    "                         n_estimators=700,\n",
    "                         max_depth=10,\n",
    "                         gamma=1,\n",
    "                         subsample=0.8,\n",
    "                         colsample_bytree=1,\n",
    "                         n_jobs=-1, \n",
    "                         random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_val)\n",
    "print('Mean Absolute Error : {0:.{1}f}'.format(mean_absolute_error(y_val, y_pred), 2))\n",
    "print('R-Square            : {0:.{1}f}'.format(r2_score(y_val, y_pred), 2))\n",
    "end = time.time()\n",
    "print('Runtime             : {0:.{1}f}sec'.format(end - start, 0))\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "y_pred_test = model.predict(x_test)\n",
    "print('Mean Absolute Error : {0:.{1}f}'.format(mean_absolute_error(y_test, y_pred_test), 2))\n",
    "print('R-Square            : {0:.{1}f}'.format(r2_score(y_test, y_pred_test), 2))\n",
    "end2 = time.time()\n",
    "print('Runtime             : {0:.{1}f}sec'.format(end2 - start, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T10:17:03.493952Z",
     "start_time": "2019-09-04T10:10:48.538342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error : 1331.12\n",
      "R-Square            : 0.98\n",
      "Runtime             : 363sec\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Mean Absolute Error : 1322.12\n",
      "R-Square            : 0.98\n",
      "Runtime             : 375sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = xgb.XGBRegressor(learning_rate=0.1, \n",
    "                         n_estimators=2100,\n",
    "                         max_depth=10,\n",
    "                         n_jobs=-1, \n",
    "                         random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_val)\n",
    "print('Mean Absolute Error : {0:.{1}f}'.format(mean_absolute_error(y_val, y_pred), 2))\n",
    "print('R-Square            : {0:.{1}f}'.format(r2_score(y_val, y_pred), 2))\n",
    "end = time.time()\n",
    "print('Runtime             : {0:.{1}f}sec'.format(end - start, 0))\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "y_pred_test = model.predict(x_test)\n",
    "print('Mean Absolute Error : {0:.{1}f}'.format(mean_absolute_error(y_test, y_pred_test), 2))\n",
    "print('R-Square            : {0:.{1}f}'.format(r2_score(y_test, y_pred_test), 2))\n",
    "end2 = time.time()\n",
    "print('Runtime             : {0:.{1}f}sec'.format(end2 - start, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T10:38:27.627452Z",
     "start_time": "2019-09-04T10:26:21.051766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "Mean Absolute Error : 1326.50\n",
      "R-Square            : 0.98\n",
      "Runtime             : 697sec\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Test\n",
      "Mean Absolute Error : 1321.54\n",
      "R-Square            : 0.98\n",
      "Runtime             : 727sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "model = xgb.XGBRegressor(learning_rate=0.05, \n",
    "                         n_estimators=4200,\n",
    "                         max_depth=10,\n",
    "                         n_jobs=-1, \n",
    "                         random_state=1)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "print('Validation')\n",
    "print('Mean Absolute Error : {0:.{1}f}'.format(mean_absolute_error(y_val, y_pred), 2))\n",
    "print('R-Square            : {0:.{1}f}'.format(r2_score(y_val, y_pred), 2))\n",
    "end = time.time()\n",
    "print('Runtime             : {0:.{1}f}sec'.format(end - start, 0))\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "y_pred_test = model.predict(x_test)\n",
    "print('Test')\n",
    "print('Mean Absolute Error : {0:.{1}f}'.format(mean_absolute_error(y_test, y_pred_test), 2))\n",
    "print('R-Square            : {0:.{1}f}'.format(r2_score(y_test, y_pred_test), 2))\n",
    "end2 = time.time()\n",
    "print('Runtime             : {0:.{1}f}sec'.format(end2 - start, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T00:29:22.642585Z",
     "start_time": "2019-09-04T23:23:00.253289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1000} 1519.4321286818501\n"
     ]
    }
   ],
   "source": [
    "grid_param = {'n_estimators' : range(100, 1001, 100)}\n",
    "\n",
    "xgb_grid = xgb.XGBRegressor(learning_rate=0.3, \n",
    "                            max_depth=10,\n",
    "                            gamma=1,\n",
    "                            subsample=0.8,\n",
    "                            colsample_bytree=1,\n",
    "                            n_jobs=-1, \n",
    "                            random_state=1)\n",
    "\n",
    "cv = KFold(n_splits=3)\n",
    "\n",
    "grid = GridSearchCV(estimator=xgb_grid,\n",
    "                          param_grid=grid_param,\n",
    "                          scoring='neg_mean_absolute_error',\n",
    "                          cv=cv,\n",
    "                          n_jobs=-1)\n",
    "\n",
    "grid.fit(x_train_val, y_train_val)\n",
    "\n",
    "print(grid.best_params_, -grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T19:26:04.370355Z",
     "start_time": "2019-09-06T19:07:20.643676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error : 1308.63\n",
      "R-Square            : 0.98\n",
      "Runtime             : 1070sec\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Mean Absolute Error : 1297.22\n",
      "R-Square            : 0.98\n",
      "Runtime             : 1124sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = xgb.XGBRegressor(learning_rate=0.05, \n",
    "                         n_estimators=6000,\n",
    "                         max_depth=10,\n",
    "                         gamma=1,\n",
    "                         subsample=0.8,\n",
    "                         colsample_bytree=1,\n",
    "                         n_jobs=-1, \n",
    "                         random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_val)\n",
    "print('Mean Absolute Error : {0:.{1}f}'.format(mean_absolute_error(y_val, y_pred), 2))\n",
    "print('R-Square            : {0:.{1}f}'.format(r2_score(y_val, y_pred), 2))\n",
    "end = time.time()\n",
    "print('Runtime             : {0:.{1}f}sec'.format(end - start, 0))\n",
    "\n",
    "print('-' * 100)\n",
    "\n",
    "y_pred_test = model.predict(x_test)\n",
    "print('Mean Absolute Error : {0:.{1}f}'.format(mean_absolute_error(y_test, y_pred_test), 2))\n",
    "print('R-Square            : {0:.{1}f}'.format(r2_score(y_test, y_pred_test), 2))\n",
    "end2 = time.time()\n",
    "print('Runtime             : {0:.{1}f}sec'.format(end2 - start, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br><br><br>"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Table of Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "608px",
    "left": "69px",
    "top": "66px",
    "width": "281px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 153,
   "position": {
    "height": "280px",
    "left": "-1px",
    "right": "20px",
    "top": "487px",
    "width": "283px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
