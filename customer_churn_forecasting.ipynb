{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Churn Forecasting in Telecommunication Industry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>1. Introduction</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the difference between costs of obtaining new customers and retaining existing customers, customer churn is a significant problem in business life.  \n",
    "<br>\n",
    "Companies struggle to launch special marketing campaigns in order to retain customers.  \n",
    "<br>\n",
    "Identifying customers which will leave the company soon may be a competitive advantage for companies.  \n",
    "<br>\n",
    "The aim of this analysis is to predict customer churn and identify customers which will leave the company soon since company wants to launch new marketing campaign for them in this scenario.  \n",
    "<br>\n",
    "Each row represents a customer, each column contains customers' attributes.  \n",
    "The raw data contains 7043 rows (customers) and 21 columns (features).  \n",
    "The 'Churn' column is our target.  \n",
    "<br>\n",
    "The data set includes information about:  \n",
    "\n",
    "Customers who left within the last month – the column is called Churn  \n",
    "Services that each customer has signed up for – phone, multiple lines, Internet, online security, online backup, device protection, tech support, and streaming TV and movies  \n",
    "Customer account information – how long they have been a customer, contract, payment method, paperless billing, monthly charges, and total charges  \n",
    "Demographic info about customers – gender, age range, and if they have partners and dependents  \n",
    "<br>\n",
    "* customerID : The Customer ID\n",
    "* Gender : Whether the customer is a male or a female\n",
    "* SeniorCitizen : Whether the customer is a senior citizen or not (1, 0)\n",
    "* Partner : Whether the customer has a partner or not (Yes, No)\n",
    "* Dependents : Whether the customer has dependents or not (Yes, No)\n",
    "* tenure : Number of months the customer has stayed with the company\n",
    "* PhoneService : Whether the customer has a phone service or not (Yes, No)\n",
    "* MultipleLines : Whether the customer has multiple lines or not (Yes, No, No phone service)\n",
    "* InternetService : Customer’s internet service provider (DSL, Fiber optic, No)\n",
    "* OnlineSecurity : Whether the customer has online security or not (Yes, No, No internet service)\n",
    "* OnlineBackup : Whether the customer has online backup or not (Yes, No, No internet service)\n",
    "* DeviceProtection : Whether the customer has device protection or not (Yes, No, No internet service)\n",
    "* TechSupport : Whether the customer has tech support or not (Yes, No, No internet service)\n",
    "* StreamingTV : Whether the customer has streaming TV or not (Yes, No, No internet service)\n",
    "* StreamingMovies : Whether the customer has streaming movies or not (Yes, No, No internet service)\n",
    "* Contract : The contract term of the customer (Month-to-month, One year, Two year)\n",
    "* Paperless : BillingWhether the customer has paperless billing or not (Yes, No)\n",
    "* PaymentMethod : The customer’s payment method (Electronic check, Mailed check, Bank transfer, Credit card\n",
    "* MonthlyCharges : The amount charged to the customer monthly\n",
    "* TotalCharges : The total amount charged to the customer\n",
    "* Churn : Whether the customer churned or not (Yes or No)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:38:50.852554Z",
     "start_time": "2019-06-24T22:38:49.624265Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "from sklearn.metrics import roc_auc_score, log_loss, precision_score, recall_score, f1_score, make_scorer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:38:52.160951Z",
     "start_time": "2019-06-24T22:38:52.119944Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of rows and columns of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw data contains 7043 rows (customers) and 21 columns (features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enabling Jupyter Notebook to show all columns in outputs and looking at the first/last 5 rows of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2. Data Preparation</h1><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2.1. Identification of Variables & Data Types</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be understood that most of the variables have object data type, there are 2 variables which have int data type and there is 1 variable with float data type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of distinct values of each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.apply(lambda x: [x.nunique()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distinct values of each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_data.apply(lambda x: [x.unique()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outputs illustrates that the most of the variables(18/21) are categorical and have 4 distinct values at most. 'Churn' is target variable and the other variables are predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'tenure', 'MontlyCharges' and 'TotalCharges' are numerical variables of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although type of 'TotalCharges' should be float, it's type is object.  \n",
    "<br>\n",
    "It may have some string values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_data['TotalCharges'].sort_values().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 11 rows which contain empty values in 'TotalCharges' column.  \n",
    "<br>\n",
    "Thus, it's type will be transformed to float after missing value treatment process in Exploratory Data Analysis step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2.2. Variable Transformations</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, 'customerID' column will be dropped since it is ineffective for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:39:01.270734Z",
     "start_time": "2019-06-24T22:39:01.264893Z"
    }
   },
   "outputs": [],
   "source": [
    "data = raw_data.drop('customerID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:39:01.964881Z",
     "start_time": "2019-06-24T22:39:01.949322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 20 columns):\n",
      "Gender              7043 non-null object\n",
      "SeniorCitizen       7043 non-null int64\n",
      "Partner             7043 non-null object\n",
      "Dependents          7043 non-null object\n",
      "tenure              7043 non-null int64\n",
      "PhoneService        7043 non-null object\n",
      "MultipleLines       7043 non-null object\n",
      "InternetService     7043 non-null object\n",
      "OnlineSecurity      7043 non-null object\n",
      "OnlineBackup        7043 non-null object\n",
      "DeviceProtection    7043 non-null object\n",
      "TechSupport         7043 non-null object\n",
      "StreamingTV         7043 non-null object\n",
      "StreamingMovies     7043 non-null object\n",
      "Contract            7043 non-null object\n",
      "PaperlessBilling    7043 non-null object\n",
      "PaymentMethod       7043 non-null object\n",
      "MonthlyCharges      7043 non-null float64\n",
      "TotalCharges        7043 non-null object\n",
      "Churn               7043 non-null object\n",
      "dtypes: float64(1), int64(2), object(17)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing 1 and 0 values in the 'MultipleLines' column with 'Yes' and 'No' since it is categorical feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:39:03.123377Z",
     "start_time": "2019-06-24T22:39:03.116108Z"
    }
   },
   "outputs": [],
   "source": [
    "data['SeniorCitizen'] = data['SeniorCitizen'].replace({1:'Yes',0:'No'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming 'tenure' column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:39:04.307506Z",
     "start_time": "2019-06-24T22:39:04.287847Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data.rename(columns={'tenure':'Tenure'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:39:04.996893Z",
     "start_time": "2019-06-24T22:39:04.973869Z"
    }
   },
   "outputs": [],
   "source": [
    "data['MultipleLines'] = data['MultipleLines'].replace({'No phone service' : 'No'})\n",
    "\n",
    "for i in range(8, 14):\n",
    "    data.iloc[:, i] = data.iloc[:, i].replace({'No internet service' : 'No'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>3. Exploratory Data Analysis</h1><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3.1. Missing Value Treatment</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing empty values with na in the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the na values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:39:06.988834Z",
     "start_time": "2019-06-24T22:39:06.944728Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data.replace('', np.nan)\n",
    "data = data.replace(' ', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:39:07.774194Z",
     "start_time": "2019-06-24T22:39:07.736598Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>52.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>20.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>80.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>25.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>56.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>19.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>25.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380</th>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>20.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5218</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>19.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6670</th>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>73.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6754</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>61.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender SeniorCitizen Partner Dependents  Tenure PhoneService  \\\n",
       "488   Female            No     Yes        Yes       0           No   \n",
       "753     Male            No      No        Yes       0          Yes   \n",
       "936   Female            No     Yes        Yes       0          Yes   \n",
       "1082    Male            No     Yes        Yes       0          Yes   \n",
       "1340  Female            No     Yes        Yes       0           No   \n",
       "3331    Male            No     Yes        Yes       0          Yes   \n",
       "3826    Male            No     Yes        Yes       0          Yes   \n",
       "4380  Female            No     Yes        Yes       0          Yes   \n",
       "5218    Male            No     Yes        Yes       0          Yes   \n",
       "6670  Female            No     Yes        Yes       0          Yes   \n",
       "6754    Male            No      No        Yes       0          Yes   \n",
       "\n",
       "     MultipleLines InternetService OnlineSecurity OnlineBackup  \\\n",
       "488             No             DSL            Yes           No   \n",
       "753             No              No             No           No   \n",
       "936             No             DSL            Yes          Yes   \n",
       "1082           Yes              No             No           No   \n",
       "1340            No             DSL            Yes          Yes   \n",
       "3331            No              No             No           No   \n",
       "3826           Yes              No             No           No   \n",
       "4380            No              No             No           No   \n",
       "5218            No              No             No           No   \n",
       "6670           Yes             DSL             No          Yes   \n",
       "6754           Yes             DSL            Yes          Yes   \n",
       "\n",
       "     DeviceProtection TechSupport StreamingTV StreamingMovies  Contract  \\\n",
       "488               Yes         Yes         Yes              No  Two year   \n",
       "753                No          No          No              No  Two year   \n",
       "936               Yes          No         Yes             Yes  Two year   \n",
       "1082               No          No          No              No  Two year   \n",
       "1340              Yes         Yes         Yes              No  Two year   \n",
       "3331               No          No          No              No  Two year   \n",
       "3826               No          No          No              No  Two year   \n",
       "4380               No          No          No              No  Two year   \n",
       "5218               No          No          No              No  One year   \n",
       "6670              Yes         Yes         Yes              No  Two year   \n",
       "6754               No         Yes          No              No  Two year   \n",
       "\n",
       "     PaperlessBilling              PaymentMethod  MonthlyCharges TotalCharges  \\\n",
       "488               Yes  Bank transfer (automatic)           52.55          NaN   \n",
       "753                No               Mailed check           20.25          NaN   \n",
       "936                No               Mailed check           80.85          NaN   \n",
       "1082               No               Mailed check           25.75          NaN   \n",
       "1340               No    Credit card (automatic)           56.05          NaN   \n",
       "3331               No               Mailed check           19.85          NaN   \n",
       "3826               No               Mailed check           25.35          NaN   \n",
       "4380               No               Mailed check           20.00          NaN   \n",
       "5218              Yes               Mailed check           19.70          NaN   \n",
       "6670               No               Mailed check           73.35          NaN   \n",
       "6754              Yes  Bank transfer (automatic)           61.90          NaN   \n",
       "\n",
       "     Churn  \n",
       "488     No  \n",
       "753     No  \n",
       "936     No  \n",
       "1082    No  \n",
       "1340    No  \n",
       "3331    No  \n",
       "3826    No  \n",
       "4380    No  \n",
       "5218    No  \n",
       "6670    No  \n",
       "6754    No  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:39:08.635617Z",
     "start_time": "2019-06-24T22:39:08.631115Z"
    }
   },
   "outputs": [],
   "source": [
    "data['TotalCharges'] = data['TotalCharges'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11 rows which have na value represent very small proportion in 7043 rows. Since tenure of the rows are 0, they can be filled with 0 to obtain missing value treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:39:09.733996Z",
     "start_time": "2019-06-24T22:39:09.720328Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender              0\n",
       "SeniorCitizen       0\n",
       "Partner             0\n",
       "Dependents          0\n",
       "Tenure              0\n",
       "PhoneService        0\n",
       "MultipleLines       0\n",
       "InternetService     0\n",
       "OnlineSecurity      0\n",
       "OnlineBackup        0\n",
       "DeviceProtection    0\n",
       "TechSupport         0\n",
       "StreamingTV         0\n",
       "StreamingMovies     0\n",
       "Contract            0\n",
       "PaperlessBilling    0\n",
       "PaymentMethod       0\n",
       "MonthlyCharges      0\n",
       "TotalCharges        0\n",
       "Churn               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the data type of 'TotalCharges':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:39:11.060684Z",
     "start_time": "2019-06-24T22:39:11.053158Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['TotalCharges'] = data['TotalCharges'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3.2. Outlier Treatment</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifying the outliers in continuous variables based on IQR Score Method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers(data, column_list):\n",
    "    for i in column_list:\n",
    "        Q1 = data[i].quantile(0.25)\n",
    "        Q3 = data[i].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        print(data[i][(data[i] < (Q1 - 1.5 * IQR)) | (data[i] > (Q3 + 1.5 * IQR))])\n",
    "find_outliers(data, ['Tenure', 'MonthlyCharges', 'TotalCharges'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that columns do not contain any outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3.3. Univariate Analysis</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, target variable should be set and other variables should be split into 2 groups as categorical and numerical variables to make the analysis easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:39:13.528122Z",
     "start_time": "2019-06-24T22:39:13.519923Z"
    }
   },
   "outputs": [],
   "source": [
    "features = data.drop('Churn', axis=1)\n",
    "target = pd.DataFrame(data['Churn'], columns=['Churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:39:14.390636Z",
     "start_time": "2019-06-24T22:39:14.384037Z"
    }
   },
   "outputs": [],
   "source": [
    "nums = features[['Tenure', 'MonthlyCharges', 'TotalCharges']]\n",
    "cats = features.drop(['Tenure', 'MonthlyCharges', 'TotalCharges'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><h3>3.3.1. Categorical</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Count%</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "round(target['Churn'].value_counts(normalize=True), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The customers who stop doing business with the company represent %27 of the data.  \n",
    "<br>\n",
    "Hence, it can be said that this is an unbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in cats.columns:\n",
    "    print(round(cats[i].value_counts(normalize=True), 2))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Pie Chart</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in cats.columns:\n",
    "    print('\\n')\n",
    "    print('\\t'*2 + i)\n",
    "    plt.pie(cats[i].value_counts(normalize = True), labels=cats[i].unique(), autopct='%1.1f%%', startangle=90)\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "    print('-'*45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs show that while some variables are balanced some are imbalanced. The imbalanced variables are as below:  \n",
    "<br>\n",
    "84% of the customers are not senior citizen.  \n",
    "70% of the customers does not have dependents.  \n",
    "71% of the customers does not have online security.  \n",
    "71% of the customers does not have tech support.  \n",
    "90% of the customers have phone service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><h3>3.3.2. Numerical</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nums.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('-----Variance-----')\n",
    "for i in nums.columns:\n",
    "    print(i + ': ' + str(round(nums[i].var(), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('-----Coefficient of Variation-----')\n",
    "for i in nums.columns:\n",
    "    print(i + ': ' + str(round((nums[i].std() / nums[i].mean()) * 100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the outputs of the 'Tenure' and 'MonthlyCharges' variables are between -0.5 and 0 or 0 and 0.5 it can be said that these variables have symmetrical distribution. However, the output of the 'TotalCharges' variable is between 0.5 and 1, thus this variable is moderately (and positively) skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums.kurtosis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All variables have low kurtosis which is an indicator that data has light tails or lack of outliers. In addition, distribution is shorter, tails are thinner than the normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b>Histogram, Box Plot</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nums.hist(bins=10, figsize=(15, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=nums['Tenure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=nums['MonthlyCharges'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=nums['TotalCharges'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3.4. Bivariate Analysis</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3.4.1. Categorical & Categorical</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Chi-Square Test</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "same = []\n",
    "for i in cats.columns:\n",
    "    cont = pd.crosstab(cats[i], target['Churn'])\n",
    "    chi2_stat, p_val, dof, ex = stats.chi2_contingency(cont)\n",
    "    print(i + ' - Churn')\n",
    "    print(\"Chi2 Stat :\" + str(chi2_stat))\n",
    "    print(\"Critical Value :\" + str(stats.chi2.ppf(q = 0.95, df = dof)))\n",
    "    if chi2_stat < stats.chi2.ppf(q = 0.95, df = dof):\n",
    "        same.append(i)\n",
    "        print(\"The two distribution are the same.\")\n",
    "    else:\n",
    "        print(\"Reject the null hypothesis that the two distribution are the same.\")\n",
    "    print(\"Degrees of Freedom :\" + str(dof))\n",
    "    print(\"P-Value :\" + str(p_val))\n",
    "    print(\"Contingency Table :\" + str(ex))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the output, it can be understood that 'Gender' and 'PhoneService' are the only variables which have the same distribution since their chi-squared statistics exceeds the critical value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<b>Bar Charts</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def categorical_summarized(dataframe, x=None, y=None, hue=None, verbose=True):\n",
    "    sns.countplot(x=x, y=y, hue=hue, data=dataframe)\n",
    "    plt.show()\n",
    "\n",
    "for i in cats.columns:\n",
    "    categorical_summarized(data, x = i, hue='Churn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3.4.2. Numerical & Numerical</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Correlation</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(nums.corr(), annot=True, cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<b>Scatter Plot</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set(style='ticks')\n",
    "\n",
    "sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3.4.3. Numerical & Categorical</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Churn'] = data['Churn'].replace({'Yes':1,'No':0})\n",
    "data.groupby('Tenure')['Churn'].mean().sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pd.DataFrame(data['Tenure'].unique(), columns=['Tenure']).sort_values(by='Tenure'), \n",
    "         data.groupby('Tenure')['Churn'].mean())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that there is negative relationship between 'Tenure' and 'Churn'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b>Bar Charts</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Churn'] = data['Churn'].replace({1:'Yes',0:'No'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(14, 4))\n",
    "data[data['Churn'] == 'No'][['Tenure', 'MonthlyCharges', 'TotalCharges']].hist(bins=10, \n",
    "                                                                               color='green', \n",
    "                                                                               ax=ax)\n",
    "data[data['Churn'] == 'Yes'][['Tenure', 'MonthlyCharges', 'TotalCharges']].hist(bins=10, \n",
    "                                                                                color='red', \n",
    "                                                                                ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>4. Data Preprocessing</h1><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>4.1. Label Encoding</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:39:17.429766Z",
     "start_time": "2019-06-24T22:39:17.425357Z"
    }
   },
   "outputs": [],
   "source": [
    "binary = []\n",
    "multi = []\n",
    "for i in cats.columns:\n",
    "    if i in ['Gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'PaperlessBilling']:\n",
    "        binary.append(i)\n",
    "    else:\n",
    "        multi.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:39:18.411461Z",
     "start_time": "2019-06-24T22:39:18.381072Z"
    }
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "target['Churn'] = le.fit_transform(target['Churn'])\n",
    "\n",
    "for i in binary:\n",
    "    features[i] = le.fit_transform(features[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>4.2. Dummification</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:39:20.042204Z",
     "start_time": "2019-06-24T22:39:19.932947Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in multi:\n",
    "    cols = []\n",
    "    for j in list(features[i].unique()):\n",
    "        cols.append(i + ':' + j)\n",
    "    ohe = OneHotEncoder(dtype='int64', sparse=False)\n",
    "    ohe_i = ohe.fit_transform(features[i].values.reshape(-1, 1))\n",
    "    ohe_i = pd.DataFrame(ohe_i, columns=cols)\n",
    "    features = pd.concat([features, ohe_i], axis=1)\n",
    "    features = features.drop(i, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>4.3. Feature Scaling</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is no outlier in dataset, standartization is a good way to improve the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:39:21.484144Z",
     "start_time": "2019-06-24T22:39:21.472825Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_scale = ['TotalCharges', 'Tenure', 'MonthlyCharges']\n",
    "std = StandardScaler()\n",
    "scaled = std.fit_transform(features[to_scale])\n",
    "scaled = pd.DataFrame(scaled, index=features.index, columns = to_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:39:22.603652Z",
     "start_time": "2019-06-24T22:39:22.599001Z"
    }
   },
   "outputs": [],
   "source": [
    "features['TotalCharges'] = scaled['TotalCharges']\n",
    "features['Tenure'] = scaled['Tenure']\n",
    "features['MonthlyCharges'] = scaled['MonthlyCharges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:39:23.616567Z",
     "start_time": "2019-06-24T22:39:23.589529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                                                                          [[0.0, 1.0]]\n",
       "SeniorCitizen                                                                   [[0.0, 1.0]]\n",
       "Partner                                                                         [[1.0, 0.0]]\n",
       "Dependents                                                                      [[0.0, 1.0]]\n",
       "Tenure                                     [[-1.2774445836787656, 0.06632741908223598, -1...\n",
       "PhoneService                                                                    [[0.0, 1.0]]\n",
       "PaperlessBilling                                                                [[1.0, 0.0]]\n",
       "MonthlyCharges                             [[-1.1603229160349193, -0.2596289419448806, -0...\n",
       "TotalCharges                               [[-0.9926105235902257, -0.17216470898960817, -...\n",
       "MultipleLines:No                                                                [[1.0, 0.0]]\n",
       "MultipleLines:Yes                                                               [[0.0, 1.0]]\n",
       "InternetService:DSL                                                             [[1.0, 0.0]]\n",
       "InternetService:Fiber optic                                                     [[0.0, 1.0]]\n",
       "InternetService:No                                                              [[0.0, 1.0]]\n",
       "OnlineSecurity:No                                                               [[1.0, 0.0]]\n",
       "OnlineSecurity:Yes                                                              [[0.0, 1.0]]\n",
       "OnlineBackup:Yes                                                                [[0.0, 1.0]]\n",
       "OnlineBackup:No                                                                 [[1.0, 0.0]]\n",
       "DeviceProtection:No                                                             [[1.0, 0.0]]\n",
       "DeviceProtection:Yes                                                            [[0.0, 1.0]]\n",
       "TechSupport:No                                                                  [[1.0, 0.0]]\n",
       "TechSupport:Yes                                                                 [[0.0, 1.0]]\n",
       "StreamingTV:No                                                                  [[1.0, 0.0]]\n",
       "StreamingTV:Yes                                                                 [[0.0, 1.0]]\n",
       "StreamingMovies:No                                                              [[1.0, 0.0]]\n",
       "StreamingMovies:Yes                                                             [[0.0, 1.0]]\n",
       "Contract:Month-to-month                                                         [[1.0, 0.0]]\n",
       "Contract:One year                                                               [[0.0, 1.0]]\n",
       "Contract:Two year                                                               [[0.0, 1.0]]\n",
       "PaymentMethod:Electronic check                                                  [[0.0, 1.0]]\n",
       "PaymentMethod:Mailed check                                                      [[0.0, 1.0]]\n",
       "PaymentMethod:Bank transfer (automatic)                                         [[1.0, 0.0]]\n",
       "PaymentMethod:Credit card (automatic)                                           [[0.0, 1.0]]\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.apply(lambda x: [x.unique()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>4.4. Train-Test Split</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:39:25.381640Z",
     "start_time": "2019-06-24T22:39:25.374012Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>5. Modeling</h1><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:39:27.127247Z",
     "start_time": "2019-06-24T22:39:27.121892Z"
    }
   },
   "outputs": [],
   "source": [
    "classifiers = {'Naive Bayes': GaussianNB(),\n",
    "               'Decision Tree': DecisionTreeClassifier(criterion='entropy', random_state=13),\n",
    "               'Logistic Reg.': LogisticRegression(random_state=12),\n",
    "               'K-Nearset N.': KNeighborsClassifier(n_jobs=-1),\n",
    "               'Linear SVC' : LinearSVC(random_state=14, max_iter=10000),\n",
    "               'Random Forest' : RandomForestClassifier(criterion='entropy', n_jobs=-1, random_state=15),\n",
    "               'Gradient B.T.': GradientBoostingClassifier(random_state=16)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:39:28.633116Z",
     "start_time": "2019-06-24T22:39:28.629004Z"
    }
   },
   "outputs": [],
   "source": [
    "model_names = list(classifiers.keys())\n",
    "accuracy = []\n",
    "roc_auc = []\n",
    "log_loss_list = []\n",
    "f1_score_list = []\n",
    "precision = []\n",
    "recall = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:39:30.124971Z",
     "start_time": "2019-06-24T22:39:30.115548Z"
    }
   },
   "outputs": [],
   "source": [
    "def results(y_test, y_pred):\n",
    "    print('Accuracy Score :' + str(accuracy_score(y_test, y_pred)) + '\\n')\n",
    "    accuracy.append(accuracy_score(y_test, y_pred))\n",
    "    print('Precision Score :' + str(precision_score(y_test, y_pred)) + '\\n')\n",
    "    precision.append(precision_score(y_test, y_pred))\n",
    "    print('Recall Score :' + str(recall_score(y_test, y_pred)) + '\\n')\n",
    "    recall.append(recall_score(y_test, y_pred))\n",
    "    print('ROC AUC :' + str(roc_auc_score(y_test,y_pred)) + '\\n')\n",
    "    roc_auc.append(roc_auc_score(y_test,y_pred))\n",
    "    print('Log-Loss :' + str(log_loss(y_test, y_pred)) + '\\n')\n",
    "    log_loss_list.append(log_loss(y_test, y_pred))\n",
    "    print('F1-Score :' + str(f1_score(y_test, y_pred)) + '\\n')\n",
    "    f1_score_list.append(f1_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred) + '\\n')\n",
    "    print('-----Confusion Matrix-----')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:39:33.051470Z",
     "start_time": "2019-06-24T22:39:31.573916Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes \n",
      "\n",
      "Accuracy Score :0.76\n",
      "\n",
      "Precision Score :0.5191441441441441\n",
      "\n",
      "Recall Score :0.7787162162162162\n",
      "\n",
      "ROC AUC :0.7661613394987602\n",
      "\n",
      "Log-Loss :8.289453185575422\n",
      "\n",
      "F1-Score :0.622972972972973\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.75      0.82      1733\n",
      "           1       0.52      0.78      0.62       592\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      2325\n",
      "   macro avg       0.71      0.77      0.72      2325\n",
      "weighted avg       0.81      0.76      0.77      2325\n",
      "\n",
      "\n",
      "-----Confusion Matrix-----\n",
      "[[1306  427]\n",
      " [ 131  461]]\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Decision Tree \n",
      "\n",
      "Accuracy Score :0.7329032258064516\n",
      "\n",
      "Precision Score :0.4762684124386252\n",
      "\n",
      "Recall Score :0.49155405405405406\n",
      "\n",
      "ROC AUC :0.6534515798256421\n",
      "\n",
      "Log-Loss :9.225305811792342\n",
      "\n",
      "F1-Score :0.483790523690773\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1733\n",
      "           1       0.48      0.49      0.48       592\n",
      "\n",
      "   micro avg       0.73      0.73      0.73      2325\n",
      "   macro avg       0.65      0.65      0.65      2325\n",
      "weighted avg       0.74      0.73      0.73      2325\n",
      "\n",
      "\n",
      "-----Confusion Matrix-----\n",
      "[[1413  320]\n",
      " [ 301  291]]\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Logistic Reg. \n",
      "\n",
      "Accuracy Score :0.8068817204301075\n",
      "\n",
      "Precision Score :0.639921722113503\n",
      "\n",
      "Recall Score :0.5523648648648649\n",
      "\n",
      "ROC AUC :0.7230953002916362\n",
      "\n",
      "Log-Loss :6.670132355803033\n",
      "\n",
      "F1-Score :0.5929283771532186\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      1733\n",
      "           1       0.64      0.55      0.59       592\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      2325\n",
      "   macro avg       0.75      0.72      0.73      2325\n",
      "weighted avg       0.80      0.81      0.80      2325\n",
      "\n",
      "\n",
      "-----Confusion Matrix-----\n",
      "[[1549  184]\n",
      " [ 265  327]]\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "K-Nearset N. \n",
      "\n",
      "Accuracy Score :0.7686021505376344\n",
      "\n",
      "Precision Score :0.546875\n",
      "\n",
      "Recall Score :0.5320945945945946\n",
      "\n",
      "ROC AUC :0.6907443544236678\n",
      "\n",
      "Log-Loss :7.992288342103755\n",
      "\n",
      "F1-Score :0.5393835616438355\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.85      1733\n",
      "           1       0.55      0.53      0.54       592\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      2325\n",
      "   macro avg       0.69      0.69      0.69      2325\n",
      "weighted avg       0.77      0.77      0.77      2325\n",
      "\n",
      "\n",
      "-----Confusion Matrix-----\n",
      "[[1472  261]\n",
      " [ 277  315]]\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Linear SVC \n",
      "\n",
      "Accuracy Score :0.8060215053763441\n",
      "\n",
      "Precision Score :0.6385068762278978\n",
      "\n",
      "Recall Score :0.5489864864864865\n",
      "\n",
      "ROC AUC :0.7214061111024469\n",
      "\n",
      "Log-Loss :6.699843131196505\n",
      "\n",
      "F1-Score :0.5903723887375114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      1733\n",
      "           1       0.64      0.55      0.59       592\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      2325\n",
      "   macro avg       0.75      0.72      0.73      2325\n",
      "weighted avg       0.80      0.81      0.80      2325\n",
      "\n",
      "\n",
      "-----Confusion Matrix-----\n",
      "[[1549  184]\n",
      " [ 267  325]]\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Random Forest \n",
      "\n",
      "Accuracy Score :0.7849462365591398\n",
      "\n",
      "Precision Score :0.6004366812227074\n",
      "\n",
      "Recall Score :0.46452702702702703\n",
      "\n",
      "ROC AUC :0.6794648983952215\n",
      "\n",
      "Log-Loss :7.427756784423685\n",
      "\n",
      "F1-Score :0.5238095238095238\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86      1733\n",
      "           1       0.60      0.46      0.52       592\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      2325\n",
      "   macro avg       0.72      0.68      0.69      2325\n",
      "weighted avg       0.77      0.78      0.78      2325\n",
      "\n",
      "\n",
      "-----Confusion Matrix-----\n",
      "[[1550  183]\n",
      " [ 317  275]]\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Gradient B.T. \n",
      "\n",
      "Accuracy Score :0.810752688172043\n",
      "\n",
      "Precision Score :0.652\n",
      "\n",
      "Recall Score :0.5506756756756757\n",
      "\n",
      "ROC AUC :0.7251358759220848\n",
      "\n",
      "Log-Loss :6.53643042740368\n",
      "\n",
      "F1-Score :0.5970695970695971\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88      1733\n",
      "           1       0.65      0.55      0.60       592\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      2325\n",
      "   macro avg       0.75      0.73      0.74      2325\n",
      "weighted avg       0.80      0.81      0.81      2325\n",
      "\n",
      "\n",
      "-----Confusion Matrix-----\n",
      "[[1559  174]\n",
      " [ 266  326]]\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf in classifiers:\n",
    "    model = classifiers[clf]\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(clf, '\\n')\n",
    "    results(y_test, y_pred)\n",
    "    print('-' * 100 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>6. Model Evaluation</h1><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>6.1. Performance Metrics</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:39:35.298856Z",
     "start_time": "2019-06-24T22:39:35.295688Z"
    }
   },
   "outputs": [],
   "source": [
    "def second(x):\n",
    "    return x[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Accuracy</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:39:37.004711Z",
     "start_time": "2019-06-24T22:39:36.998700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient B.T.\t: 0.811\n",
      "Logistic Reg.\t: 0.807\n",
      "Linear SVC\t: 0.806\n",
      "Random Forest\t: 0.785\n",
      "K-Nearset N.\t: 0.769\n",
      "Naive Bayes\t: 0.760\n",
      "Decision Tree\t: 0.733\n"
     ]
    }
   ],
   "source": [
    "for i, j in sorted(zip(model_names, accuracy), key=second, reverse=True):\n",
    "    print(i + '\\t' + ': {0:.{1}f}'.format(j, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><b>ROC AUC</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:39:38.492032Z",
     "start_time": "2019-06-24T22:39:38.487355Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\t: 0.766\n",
      "Gradient B.T.\t: 0.725\n",
      "Logistic Reg.\t: 0.723\n",
      "Linear SVC\t: 0.721\n",
      "K-Nearset N.\t: 0.691\n",
      "Random Forest\t: 0.679\n",
      "Decision Tree\t: 0.653\n"
     ]
    }
   ],
   "source": [
    "for i, j in sorted(zip(model_names, roc_auc), key=second, reverse=True):\n",
    "    print(i + '\\t' + ': {0:.{1}f}'.format(j, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><b>Log-Loss</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:39:39.994795Z",
     "start_time": "2019-06-24T22:39:39.988581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient B.T.\t: 6.536\n",
      "Logistic Reg.\t: 6.670\n",
      "Linear SVC\t: 6.700\n",
      "Random Forest\t: 7.428\n",
      "K-Nearset N.\t: 7.992\n",
      "Naive Bayes\t: 8.289\n",
      "Decision Tree\t: 9.225\n"
     ]
    }
   ],
   "source": [
    "for i, j in sorted(zip(model_names, log_loss_list), key=second, reverse=False):\n",
    "    print(i + '\\t' + ': {0:.{1}f}'.format(j, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><b>F1-Score</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:39:41.499966Z",
     "start_time": "2019-06-24T22:39:41.493538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\t: 0.623\n",
      "Gradient B.T.\t: 0.597\n",
      "Logistic Reg.\t: 0.593\n",
      "Linear SVC\t: 0.590\n",
      "K-Nearset N.\t: 0.539\n",
      "Random Forest\t: 0.524\n",
      "Decision Tree\t: 0.484\n"
     ]
    }
   ],
   "source": [
    "for i, j in sorted(zip(model_names, f1_score_list), key=second, reverse=True):\n",
    "    print(i + '\\t' + ': {0:.{1}f}'.format(j, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><b>Sensitivity</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:39:43.071385Z",
     "start_time": "2019-06-24T22:39:43.065147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\t: 0.779\n",
      "Logistic Reg.\t: 0.552\n",
      "Gradient B.T.\t: 0.551\n",
      "Linear SVC\t: 0.549\n",
      "K-Nearset N.\t: 0.532\n",
      "Decision Tree\t: 0.492\n",
      "Random Forest\t: 0.465\n"
     ]
    }
   ],
   "source": [
    "for i, j in sorted(zip(model_names, recall), key=second, reverse=True):\n",
    "    print(i + '\\t' + ': {0:.{1}f}'.format(j, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><b>Precision</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:39:44.589926Z",
     "start_time": "2019-06-24T22:39:44.585376Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient B.T.\t: 0.652\n",
      "Logistic Reg.\t: 0.640\n",
      "Linear SVC\t: 0.639\n",
      "Random Forest\t: 0.600\n",
      "K-Nearset N.\t: 0.547\n",
      "Naive Bayes\t: 0.519\n",
      "Decision Tree\t: 0.476\n"
     ]
    }
   ],
   "source": [
    "for i, j in sorted(zip(model_names, precision), key=second, reverse=True):\n",
    "    print(i + '\\t' + ': {0:.{1}f}'.format(j, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The company wants to detect customers who will leave soon and offer them special marketing campaigns.  \n",
    "<br>\n",
    "Thus, precision is the most suitable option to evaluate the performance of models since the data is imbalance and the aim is to identify customers will leave as accurately as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<h2>6.2. k-Fold Cross-Validation</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:40:02.180370Z",
     "start_time": "2019-06-24T22:39:46.765459Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient B.T.\t: 0.665\n",
      "Logistic Reg.\t: 0.655\n",
      "Linear SVC\t: 0.655\n",
      "Random Forest\t: 0.634\n",
      "K-Nearset N.\t: 0.568\n",
      "Naive Bayes\t: 0.523\n",
      "Decision Tree\t: 0.508\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "\n",
    "for clf in classifiers:\n",
    "    scores = []\n",
    "    model = classifiers[clf]\n",
    "    cv = KFold(n_splits=10, random_state=32)\n",
    "    \n",
    "    for train_index, test_index in cv.split(features.values):\n",
    "        x_train, x_test, y_train, y_test = features.iloc[train_index], features.iloc[test_index], \\\n",
    "                                            target.iloc[train_index], target.iloc[test_index]\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        scores.append(precision_score(y_test, y_pred))\n",
    "    \n",
    "    cv_scores.append(sum(scores) / len(scores))\n",
    "\n",
    "for i, j in sorted(zip(model_names, cv_scores), key=second, reverse=True):\n",
    "    print(i + '\\t' + ': {0:.{1}f}'.format(j, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would seem that Gradient Boosting Tree is the most suitable model for this case according to the precision metric.  \n",
    "<br>\n",
    "Next step is increasing performance of the model by trying different parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<h2>6.3. Hyperparameter Tuning</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:41:22.758112Z",
     "start_time": "2019-06-24T22:40:04.047488Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 20} 0.6560\n",
      "{'n_estimators': 20} 0.7593\n",
      "{'n_estimators': 20} 0.6863\n",
      "{'n_estimators': 20} 0.6612\n",
      "{'n_estimators': 20} 0.6604\n",
      "{'n_estimators': 20} 0.6250\n",
      "{'n_estimators': 20} 0.7426\n",
      "{'n_estimators': 20} 0.6881\n",
      "{'n_estimators': 20} 0.6637\n",
      "{'n_estimators': 20} 0.7477\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, random_state=54)\n",
    "\n",
    "for train_index, test_index in kfold.split(features.values):\n",
    "    x_train, x_test, y_train, y_test = features.iloc[train_index], features.iloc[test_index], \\\n",
    "                                        target.iloc[train_index], target.iloc[test_index]\n",
    "        \n",
    "    clf = GradientBoostingClassifier(random_state=99)\n",
    "    \n",
    "    parameters = {'n_estimators':range(20, 81, 10)}\n",
    "\n",
    "    grid = GridSearchCV(clf, parameters, scoring='precision', cv=10, n_jobs=-1, iid=False)\n",
    "\n",
    "    grid = grid.fit(x_train, y_train)\n",
    "\n",
    "    model = grid.best_estimator_\n",
    "    \n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    print(grid.best_params_, '{0:.{1}f}'.format(precision_score(y_test, y_pred), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that even though there is only one parameter tuned and others were at their default value, results vary significantly from 0.625 to 0.759 depending on variety among folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, hyperparameter tuning will be done with k-fold cross-validation in order to maintain consistency of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:42:24.178908Z",
     "start_time": "2019-06-24T22:42:02.027708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0.6878\n",
      "30 0.6722\n",
      "40 0.6672\n",
      "50 0.6642\n",
      "60 0.6613\n",
      "70 0.6557\n",
      "80 0.6570\n"
     ]
    }
   ],
   "source": [
    "for i in range(20, 81, 10):\n",
    "    scores = []\n",
    "    kfold = KFold(n_splits=10, random_state=54)\n",
    "    for train_index, test_index in kfold.split(features.values):\n",
    "        x_train, x_test, y_train, y_test = features.iloc[train_index], features.iloc[test_index], \\\n",
    "                                            target.iloc[train_index], target.iloc[test_index]\n",
    "        \n",
    "        model = GradientBoostingClassifier(learning_rate=0.1, \n",
    "                                           n_estimators=i,\n",
    "                                           min_samples_split=40,\n",
    "                                           min_samples_leaf=40,\n",
    "                                           max_depth=5,\n",
    "                                           max_features=\"sqrt\",\n",
    "                                           subsample=0.8,\n",
    "                                           random_state=99)\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        scores.append(precision_score(y_test, y_pred))\n",
    "    \n",
    "    print(i, '{0:.{1}f}'.format(sum(scores) / len(scores), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:42:50.394876Z",
     "start_time": "2019-06-24T22:42:27.636280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0.7833\n",
      "30 0.7210\n",
      "40 0.6958\n",
      "50 0.6850\n",
      "60 0.6777\n",
      "70 0.6719\n",
      "80 0.6673\n"
     ]
    }
   ],
   "source": [
    "for i in range(20, 81, 10):\n",
    "    scores = []\n",
    "    kfold = KFold(n_splits=10, random_state=54)\n",
    "    for train_index, test_index in kfold.split(features.values):\n",
    "        x_train, x_test, y_train, y_test = features.iloc[train_index], features.iloc[test_index], \\\n",
    "                                            target.iloc[train_index], target.iloc[test_index]\n",
    "        \n",
    "        model = GradientBoostingClassifier(learning_rate=0.05, \n",
    "                                           n_estimators=i,\n",
    "                                           min_samples_split=40,\n",
    "                                           min_samples_leaf=40,\n",
    "                                           max_depth=5,\n",
    "                                           max_features=\"sqrt\",\n",
    "                                           subsample=0.8,\n",
    "                                           random_state=99)\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        scores.append(precision_score(y_test, y_pred))\n",
    "    \n",
    "    print(i, '{0:.{1}f}'.format(sum(scores) / len(scores), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:43:15.215985Z",
     "start_time": "2019-06-24T22:42:52.347188Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0.0000\n",
      "30 0.0000\n",
      "40 0.0000\n",
      "50 0.0000\n",
      "60 0.6500\n",
      "70 0.8707\n",
      "80 0.8547\n"
     ]
    }
   ],
   "source": [
    "for i in range(20, 81, 10):\n",
    "    scores = []\n",
    "    kfold = KFold(n_splits=10, random_state=54)\n",
    "    for train_index, test_index in kfold.split(features.values):\n",
    "        x_train, x_test, y_train, y_test = features.iloc[train_index], features.iloc[test_index], \\\n",
    "                                            target.iloc[train_index], target.iloc[test_index]\n",
    "        \n",
    "        model = GradientBoostingClassifier(learning_rate=0.01, \n",
    "                                           n_estimators=i,\n",
    "                                           min_samples_split=40,\n",
    "                                           min_samples_leaf=40,\n",
    "                                           max_depth=5,\n",
    "                                           max_features=\"sqrt\",\n",
    "                                           subsample=0.8,\n",
    "                                           random_state=99)\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        scores.append(precision_score(y_test, y_pred))\n",
    "    \n",
    "    print(i, '{0:.{1}f}'.format(sum(scores) / len(scores), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:44:49.469588Z",
     "start_time": "2019-06-24T22:43:23.119364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 0.6556\n",
      "62 0.6386\n",
      "63 0.8417\n",
      "64 0.8931\n",
      "65 0.8876\n",
      "66 0.8812\n",
      "67 0.8603\n",
      "68 0.8628\n",
      "69 0.8686\n",
      "70 0.8707\n",
      "71 0.8802\n",
      "72 0.8773\n",
      "73 0.8689\n",
      "74 0.8732\n",
      "75 0.8732\n",
      "76 0.8540\n",
      "77 0.8602\n",
      "78 0.8650\n",
      "79 0.8684\n"
     ]
    }
   ],
   "source": [
    "for i in range(61, 80):\n",
    "    scores = []\n",
    "    kfold = KFold(n_splits=10, random_state=54)\n",
    "    for train_index, test_index in kfold.split(features.values):\n",
    "        x_train, x_test, y_train, y_test = features.iloc[train_index], features.iloc[test_index], \\\n",
    "                                            target.iloc[train_index], target.iloc[test_index]\n",
    "        \n",
    "        model = GradientBoostingClassifier(learning_rate=0.01, \n",
    "                                           n_estimators=i,\n",
    "                                           min_samples_split=40,\n",
    "                                           min_samples_leaf=40,\n",
    "                                           max_depth=5,\n",
    "                                           max_features=\"sqrt\",\n",
    "                                           subsample=0.8,\n",
    "                                           random_state=99)\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        scores.append(precision_score(y_test, y_pred))\n",
    "    \n",
    "    print(i, '{0:.{1}f}'.format(sum(scores) / len(scores), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:45:38.157374Z",
     "start_time": "2019-06-24T22:44:52.313216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.8931\n",
      "6 0.8667\n",
      "7 0.8768\n",
      "8 0.8676\n",
      "9 0.8703\n",
      "10 0.8768\n",
      "11 0.8648\n"
     ]
    }
   ],
   "source": [
    "for i in range(5, 12):\n",
    "    scores = []\n",
    "    kfold = KFold(n_splits=10, random_state=54)\n",
    "    for train_index, test_index in kfold.split(features.values):\n",
    "        x_train, x_test, y_train, y_test = features.iloc[train_index], features.iloc[test_index], \\\n",
    "                                            target.iloc[train_index], target.iloc[test_index]\n",
    "        \n",
    "        model = GradientBoostingClassifier(learning_rate=0.01, \n",
    "                                           n_estimators=64,\n",
    "                                           min_samples_split=40,\n",
    "                                           min_samples_leaf=40,\n",
    "                                           max_depth=i,\n",
    "                                           max_features=\"sqrt\",\n",
    "                                           subsample=0.8,\n",
    "                                           random_state=99)\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        scores.append(precision_score(y_test, y_pred))\n",
    "    \n",
    "    print(i, '{0:.{1}f}'.format(sum(scores) / len(scores), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:46:35.039075Z",
     "start_time": "2019-06-24T22:45:41.111235Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 0.8931\n",
      "60 0.8931\n",
      "80 0.8931\n",
      "100 0.9203\n",
      "120 0.8860\n",
      "140 0.8918\n",
      "160 0.8979\n",
      "180 0.8994\n",
      "200 0.8907\n",
      "220 0.7739\n",
      "240 0.8080\n",
      "260 0.7752\n",
      "280 0.8822\n",
      "300 0.7757\n"
     ]
    }
   ],
   "source": [
    "for i in range(40, 301, 20):\n",
    "    scores = []\n",
    "    kfold = KFold(n_splits=10, random_state=54)\n",
    "    for train_index, test_index in kfold.split(features.values):\n",
    "        x_train, x_test, y_train, y_test = features.iloc[train_index], features.iloc[test_index], \\\n",
    "                                            target.iloc[train_index], target.iloc[test_index]\n",
    "        \n",
    "        model = GradientBoostingClassifier(learning_rate=0.01, \n",
    "                                           n_estimators=64,\n",
    "                                           min_samples_split=i,\n",
    "                                           min_samples_leaf=40,\n",
    "                                           max_depth=5,\n",
    "                                           max_features=\"sqrt\",\n",
    "                                           subsample=0.8,\n",
    "                                           random_state=99)\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        scores.append(precision_score(y_test, y_pred))\n",
    "    \n",
    "    print(i, '{0:.{1}f}'.format(sum(scores) / len(scores), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:49:17.698240Z",
     "start_time": "2019-06-24T22:46:37.715731Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 0.9267\n",
      "82 0.9242\n",
      "83 0.8966\n",
      "84 0.8817\n",
      "85 0.8959\n",
      "86 0.8992\n",
      "87 0.9149\n",
      "88 0.9242\n",
      "89 0.8217\n",
      "90 0.8159\n",
      "91 0.9359\n",
      "92 0.8964\n",
      "93 0.8798\n",
      "94 0.9274\n",
      "95 0.8842\n",
      "96 0.9143\n",
      "97 0.9110\n",
      "98 0.9304\n",
      "99 0.9335\n",
      "100 0.9203\n",
      "101 0.9123\n",
      "102 0.9130\n",
      "103 0.8955\n",
      "104 0.8943\n",
      "105 0.8955\n",
      "106 0.8927\n",
      "107 0.8952\n",
      "108 0.8837\n",
      "109 0.8726\n",
      "110 0.8952\n",
      "111 0.9005\n",
      "112 0.8863\n",
      "113 0.8818\n",
      "114 0.8607\n",
      "115 0.8863\n",
      "116 0.8839\n",
      "117 0.8957\n",
      "118 0.8912\n",
      "119 0.9037\n"
     ]
    }
   ],
   "source": [
    "for i in range(81, 120):\n",
    "    scores = []\n",
    "    kfold = KFold(n_splits=10, random_state=54)\n",
    "    for train_index, test_index in kfold.split(features.values):\n",
    "        x_train, x_test, y_train, y_test = features.iloc[train_index], features.iloc[test_index], \\\n",
    "                                            target.iloc[train_index], target.iloc[test_index]\n",
    "        \n",
    "        model = GradientBoostingClassifier(learning_rate=0.01, \n",
    "                                           n_estimators=64,\n",
    "                                           min_samples_split=i,\n",
    "                                           min_samples_leaf=40,\n",
    "                                           max_depth=5,\n",
    "                                           max_features=\"sqrt\",\n",
    "                                           subsample=0.8,\n",
    "                                           random_state=99)\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        scores.append(precision_score(y_test, y_pred))\n",
    "    \n",
    "    print(i, '{0:.{1}f}'.format(sum(scores) / len(scores), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:50:21.643368Z",
     "start_time": "2019-06-24T22:49:20.707284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.9006\n",
      "20 0.8989\n",
      "30 0.8879\n",
      "40 0.9359\n",
      "50 0.9028\n",
      "60 0.8942\n",
      "70 0.8848\n",
      "80 0.8764\n",
      "90 0.8706\n",
      "100 0.8319\n",
      "110 0.7590\n",
      "120 0.7985\n",
      "130 0.6500\n",
      "140 0.5000\n",
      "150 0.1000\n",
      "160 0.0000\n"
     ]
    }
   ],
   "source": [
    "for i in range(10, 161, 10):\n",
    "    scores = []\n",
    "    kfold = KFold(n_splits=10, random_state=54)\n",
    "    for train_index, test_index in kfold.split(features.values):\n",
    "        x_train, x_test, y_train, y_test = features.iloc[train_index], features.iloc[test_index], \\\n",
    "                                            target.iloc[train_index], target.iloc[test_index]\n",
    "        \n",
    "        model = GradientBoostingClassifier(learning_rate=0.01, \n",
    "                                           n_estimators=64,\n",
    "                                           min_samples_split=91,\n",
    "                                           min_samples_leaf=i,\n",
    "                                           max_depth=5,\n",
    "                                           max_features=\"sqrt\",\n",
    "                                           subsample=0.8,\n",
    "                                           random_state=99)\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        scores.append(precision_score(y_test, y_pred))\n",
    "    \n",
    "    print(i, '{0:.{1}f}'.format(sum(scores) / len(scores), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:52:41.658586Z",
     "start_time": "2019-06-24T22:51:23.325165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 0.8968\n",
      "32 0.9073\n",
      "33 0.9041\n",
      "34 0.9040\n",
      "35 0.9083\n",
      "36 0.9240\n",
      "37 0.9048\n",
      "38 0.9071\n",
      "39 0.8956\n",
      "40 0.9359\n",
      "41 0.8333\n",
      "42 0.8767\n",
      "43 0.9190\n",
      "44 0.8774\n",
      "45 0.9415\n",
      "46 0.9465\n",
      "47 0.9008\n",
      "48 0.7959\n",
      "49 0.8250\n"
     ]
    }
   ],
   "source": [
    "for i in range(31, 50):\n",
    "    scores = []\n",
    "    kfold = KFold(n_splits=10, random_state=54)\n",
    "    for train_index, test_index in kfold.split(features.values):\n",
    "        x_train, x_test, y_train, y_test = features.iloc[train_index], features.iloc[test_index], \\\n",
    "                                            target.iloc[train_index], target.iloc[test_index]\n",
    "        \n",
    "        model = GradientBoostingClassifier(learning_rate=0.01, \n",
    "                                           n_estimators=64,\n",
    "                                           min_samples_split=91,\n",
    "                                           min_samples_leaf=i,\n",
    "                                           max_depth=5,\n",
    "                                           max_features=\"sqrt\",\n",
    "                                           subsample=0.8,\n",
    "                                           random_state=99)\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        scores.append(precision_score(y_test, y_pred))\n",
    "    \n",
    "    print(i, '{0:.{1}f}'.format(sum(scores) / len(scores), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:58:30.470525Z",
     "start_time": "2019-06-24T22:56:19.724880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.9465\n",
      "7 0.8595\n",
      "9 0.8767\n",
      "11 0.8727\n",
      "13 0.8672\n",
      "15 0.8573\n",
      "17 0.8577\n",
      "19 0.8535\n",
      "21 0.8572\n",
      "23 0.8591\n",
      "25 0.8524\n",
      "27 0.8531\n",
      "29 0.8481\n",
      "31 0.8534\n",
      "33 0.8531\n"
     ]
    }
   ],
   "source": [
    "for i in range(5, 34, 2):\n",
    "    scores = []\n",
    "    kfold = KFold(n_splits=10, random_state=54)\n",
    "    for train_index, test_index in kfold.split(features.values):\n",
    "        x_train, x_test, y_train, y_test = features.iloc[train_index], features.iloc[test_index], \\\n",
    "                                            target.iloc[train_index], target.iloc[test_index]\n",
    "        \n",
    "        model = GradientBoostingClassifier(learning_rate=0.01, \n",
    "                                           n_estimators=64,\n",
    "                                           min_samples_split=91,\n",
    "                                           min_samples_leaf=46,\n",
    "                                           max_depth=5,\n",
    "                                           max_features=i,\n",
    "                                           subsample=0.8,\n",
    "                                           random_state=99)\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        scores.append(precision_score(y_test, y_pred))\n",
    "    \n",
    "    print(i, '{0:.{1}f}'.format(sum(scores) / len(scores), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T22:59:25.901933Z",
     "start_time": "2019-06-24T22:58:47.799031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 0.8529\n",
      "0.65 0.8864\n",
      "0.7 0.8952\n",
      "0.75 0.9220\n",
      "0.8 0.9465\n",
      "0.85 0.8749\n",
      "0.9 0.8994\n",
      "0.95 0.9454\n",
      "1.0 0.8912\n"
     ]
    }
   ],
   "source": [
    "for i in [0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]:\n",
    "    scores = []\n",
    "    kfold = KFold(n_splits=10, random_state=54)\n",
    "    for train_index, test_index in kfold.split(features.values):\n",
    "        x_train, x_test, y_train, y_test = features.iloc[train_index], features.iloc[test_index], \\\n",
    "                                            target.iloc[train_index], target.iloc[test_index]\n",
    "        \n",
    "        model = GradientBoostingClassifier(learning_rate=0.01, \n",
    "                                           n_estimators=64,\n",
    "                                           min_samples_split=91,\n",
    "                                           min_samples_leaf=46,\n",
    "                                           max_depth=5,\n",
    "                                           max_features=5,\n",
    "                                           subsample=i,\n",
    "                                           random_state=99)\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        scores.append(precision_score(y_test, y_pred))\n",
    "    \n",
    "    print(i, '{0:.{1}f}'.format(sum(scores) / len(scores), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T23:00:39.609120Z",
     "start_time": "2019-06-24T23:00:35.727921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score: 0.95\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "model = GradientBoostingClassifier(learning_rate=0.01,\n",
    "                                   n_estimators=64,\n",
    "                                   max_depth=5,\n",
    "                                   min_samples_split=91,\n",
    "                                   min_samples_leaf=46,\n",
    "                                   max_features=5,\n",
    "                                   subsample=0.8,\n",
    "                                   random_state=99)\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=32)\n",
    "    \n",
    "for train_index, test_index in cv.split(features.values):\n",
    "    x_train, x_test, y_train, y_test = features.iloc[train_index], features.iloc[test_index], \\\n",
    "                                        target.iloc[train_index], target.iloc[test_index]\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    scores.append(precision_score(y_test, y_pred))\n",
    "    \n",
    "print('Precision Score: {0:.{1}f}'.format(sum(scores) / len(scores), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>7. Conclusion</h1><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this study is to predict customer churn and identify customers which will leave the company soon as accurately as possible.  \n",
    "<br>\n",
    "In Data Preparation stage, columns which are irrelevant was dropped and necessary feature transformation was made.  \n",
    "<br>\n",
    "In Exploratory Data Analysis stage, missing values in features was identified and replaced with appropriate values, outliers which may be occurred in features was detected. In addition, univariate and bivariate analysis was applied in order to observing distributions of features and relationships among attributes.  \n",
    "<br>\n",
    "In Data Preprocessing stage, binary features transformed into numerical, dummification of categorical features which have more than two distinct value was made and standard scaling was applied to numerical features in order to increase performance of machine learning models. Also, data was split as train and test for modeling.  \n",
    "<br>\n",
    "In Modeling stage, machine learning models related to classification was applied and their performance scores was printed.  \n",
    "<br>\n",
    "In Model Evaluation stage, performance metrics of models was compared each other and metrics which is most suitable for the problem was chosen. Furthermore, Cross-Validation was applied in order to exhibit the real performance of the models. It was understood that Gradient Boosting Tree has higher performance for this case. Afterwards, increasing the performance of the model was tried by tuning the parameters.  \n",
    "\n",
    "<br>\n",
    "Finally, the model gives precision score of 0.95 which means that thanks to this model 95% of the customers who will be chosen by the model and  will be presented new marketing campaign will be the actual customers who will quit doing business with the company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>8. References</h1><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Lakshmanan, S., (2019, April 25). *Exploratory Data Analysis*. Retrieved from https://towardsdatascience.com/exploratory-data-analysis-in-python-ebdf643a33f6\n",
    "<br><br>\n",
    "* Swalin, A., (2018, May 3). *Choosing the Right Metric for Evaluating Machine Learning Models*. Retrieved from https://medium.com/usf-msds/choosing-the-right-metric-for-evaluating-machine-learning-models-part-2-86d5649a5428\n",
    "<br><br>\n",
    "* Boyle, T., (2019, Feb 4). *Dealing with Imbalanced Data*. Retrieved from https://towardsdatascience.com/methods-for-dealing-with-imbalanced-data-5b761be45a18\n",
    "<br><br>\n",
    "* https://www.saedsayad.com/data_mining_map.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Table of Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "608px",
    "left": "69px",
    "top": "66px",
    "width": "304px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 153,
   "position": {
    "height": "205px",
    "left": "1px",
    "right": "20px",
    "top": "618px",
    "width": "303px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
